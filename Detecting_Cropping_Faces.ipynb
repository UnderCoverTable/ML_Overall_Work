{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to the raw images\n",
    "path_sameed_raw = \"C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Sameed\" \n",
    "path_unknown_raw = \"C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\"\n",
    "\n",
    "#Get the names of all the images\n",
    "images_sameed = os.listdir(path_sameed_raw) \n",
    "images_unknown = os.listdir(path_unknown_raw)\n",
    "\n",
    "#Store the paths of all the cropped images we will save later\n",
    "paths_sameed_cropped = []\n",
    "paths_unknown_cropped = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for img in enumerate(images_sameed):\n",
    "\n",
    "    # To ignore the first 2 folders in the directory\n",
    "    if(img[1] == \"Cropped\" or img[1] == \"Detected\"):\n",
    "        continue\n",
    "\n",
    "    #Open the image and extract the coordinates of the detected face\n",
    "    image = cv2.imread(path_sameed_raw + \"\\\\\" + img[1])\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=3,\n",
    "        minSize=(64, 64)\n",
    "    )\n",
    "    \n",
    "    # This is to select the highest detected area, in case there are false positives.\n",
    "    # As in this scenario it is highly likely that the greater area will contain the face rather then\n",
    "    # the smaller falsepostive\n",
    "\n",
    "    if(len(faces) > 1):\n",
    "        cur_max = 0\n",
    "        face = 0\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            length = math.sqrt((x - (x+w))**2 + (y - (y+h))**2 )\n",
    "            \n",
    "            if length > cur_max:\n",
    "                cur_max = length\n",
    "                face = [x,y,w,h]\n",
    "\n",
    "        faces = np.array([face])\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "    \n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2) # Draw a rectangle around the detected area (face)\n",
    "\n",
    "        roi_color = image[y+2:y+2 + h-3, x+2:x+2 + w-3] # The pixel area containing the face\n",
    "        \n",
    "        # Path where image will be saved\n",
    "        cropped_img_path = path_sameed_raw + \"\\\\Cropped\" + \"\\\\Sameed_\" + str(img[0]-1) + \"_.jpg\"\n",
    "        paths_sameed_cropped.append(cropped_img_path.replace(\"\\\\\",chr(92)))\n",
    "\n",
    "        # Resize each image to 64x64 before saving it to the path\n",
    "        cropped_img = cv2.resize(roi_color, (64,64))\n",
    "        cv2.imwrite(cropped_img_path, cropped_img)\n",
    "\n",
    "    # Save the uncropped image with detected face\n",
    "    detected_img_path = path_sameed_raw + \"\\\\Detected\" + \"\\\\Sameed_\" + str(img[0]-1) + \"_.jpg\"\n",
    "    cv2.imwrite(detected_img_path, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store all the paths for the unknown images\n",
    "for unknowns in enumerate(images_unknown):\n",
    "    if(unknowns[1] == \"Cropped\"):\n",
    "        continue\n",
    "    \n",
    "    path = path_unknown_raw + \"\\\\\" + unknowns[1]\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    img_resize = cv2.resize(image, (64,64))\n",
    "    \n",
    "    new_path = path_unknown_raw+\"\\\\\"+\"Cropped\"+\"\\\\Unknown_\"+str(unknowns[0])+\"_.jpg\"\n",
    "    cv2.imwrite(new_path, img_resize)\n",
    "\n",
    "    np = new_path.replace(\"\\\\\",chr(92))\n",
    "    paths_unknown_cropped.append(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_0_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_1_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_2_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_3_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_4_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_5_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_6_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_7_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_8_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_9_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_10_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_11_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_12_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_13_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_14_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_15_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_16_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_17_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_18_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_19_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_20_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_21_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_22_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_23_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_24_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_25_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_26_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_27_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_28_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_29_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_30_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_31_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_32_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_33_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_34_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_35_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_36_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_37_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_38_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_39_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_40_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_41_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_42_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_43_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_44_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_45_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_46_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_47_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_48_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_49_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_50_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_51_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_52_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_53_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_54_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_55_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_56_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_57_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_58_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_59_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_60_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_61_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_62_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_63_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_64_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_65_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_66_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_67_.jpg', 'C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Dataset\\\\Unknown\\\\Cropped\\\\Unknown_68_.jpg']\n",
      "69\n",
      "[]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(paths_unknown_cropped)\n",
    "print(len(paths_unknown_cropped))\n",
    "\n",
    "\n",
    "print(paths_sameed_cropped)\n",
    "print(len(paths_sameed_cropped))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
