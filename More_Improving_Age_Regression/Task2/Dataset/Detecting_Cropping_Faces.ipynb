{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to the raw images\n",
    "path_sameed_raw = \"C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Me_NotMe\\\\Dataset\\\\Sameed\" \n",
    "path_unknown_raw = \"C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Me_NotMe\\\\Dataset\\\\Unknown\"\n",
    "path_arham_raw = \"C:\\\\Users\\\\Sameed\\\\Desktop\\\\ML_Overall_Work\\\\Me_NotMe\\\\Dataset\\\\Arham\"\n",
    "\n",
    "#Get the names of all the images\n",
    "images_sameed = os.listdir(path_sameed_raw) \n",
    "images_unknown = os.listdir(path_unknown_raw)\n",
    "images_arham = os.listdir(path_arham_raw)\n",
    "\n",
    "#Store the paths of all the cropped images we will save later\n",
    "paths_sameed_cropped = []\n",
    "paths_unknown_cropped = []\n",
    "paths_arham_cropped = []\n",
    "\n",
    "img_dim = 64 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sameed_ages = []\n",
    "sameed_expressions = []\n",
    "\n",
    "for file in os.listdir(path_sameed_raw + \"\\\\Cropped\"):\n",
    "    os.remove(os.path.join(path_sameed_raw + \"\\\\Cropped\", file))\n",
    "\n",
    "for file in os.listdir(path_sameed_raw + \"\\\\Detected\"):\n",
    "    os.remove(os.path.join(path_sameed_raw + \"\\\\Detected\", file))\n",
    "\n",
    "\n",
    "\n",
    "for img in enumerate(images_sameed):\n",
    "\n",
    "    # To ignore the first 2 folders in the directory\n",
    "    if(img[1] == \"Cropped\" or img[1] == \"Detected\"):\n",
    "        continue\n",
    "\n",
    "    if(img[1][0] == \"N\"):\n",
    "        exp = \"N\"\n",
    "        sameed_expressions.append(\"Not Smiling\")\n",
    "    else:\n",
    "        exp = \"S\"\n",
    "        sameed_expressions.append(\"Smiling\")\n",
    "\n",
    "    \n",
    "\n",
    "    age = \"\"\n",
    "    for i in range(2,len(img[1])):\n",
    "        if(img[1][i] == \"_\"):\n",
    "            break\n",
    "        else:\n",
    "            age += img[1][i]\n",
    "\n",
    "    sameed_ages.append(age)\n",
    "\n",
    "    #Open the image and extract the coordinates of the detected face\n",
    "    image = cv2.imread(path_sameed_raw + \"\\\\\" + img[1])\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=3,\n",
    "        minSize=(img_dim, img_dim)\n",
    "    )\n",
    "    \n",
    "    # This is to select the highest detected area, in case there are false positives.\n",
    "    # As in this scenario it is highly likely that the greater area will contain the face rather then\n",
    "    # the smaller falsepostive\n",
    "\n",
    "    if(len(faces) > 1):\n",
    "        cur_max = 0\n",
    "        face = 0\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            length = math.sqrt((x - (x+w))**2 + (y - (y+h))**2 )\n",
    "            \n",
    "            if length > cur_max:\n",
    "                cur_max = length\n",
    "                face = [x,y,w,h]\n",
    "\n",
    "        faces = np.array([face])\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "    \n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2) # Draw a rectangle around the detected area (face)\n",
    "\n",
    "        roi_color = image[y+2:y+2 + h-3, x+2:x+2 + w-3] # The pixel area containing the face\n",
    "        \n",
    "        # Path where image will be saved\n",
    "        cropped_img_path = path_sameed_raw + \"\\\\Cropped\\\\\" + age + \"_\" + exp + \"_\" + \"Sameed_\" + str(img[0]-1) + \"_.jpg\"\n",
    "        paths_sameed_cropped.append(cropped_img_path.replace(\"\\\\\",chr(92)))\n",
    "        \n",
    "\n",
    "        # Resize each image to 64x64 before saving it to the path\n",
    "        cropped_img = cv2.resize(roi_color, (img_dim,img_dim))\n",
    "        cv2.imwrite(cropped_img_path, cropped_img)\n",
    "\n",
    "    # Save the uncropped image with detected face\n",
    "    detected_img_path = path_sameed_raw + \"\\\\Detected\\\\\" + age + \"_\" + exp + \"_\" + \"Sameed_\" + str(img[0]-1) + \"_.jpg\"\n",
    "    cv2.imwrite(detected_img_path, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(path_arham_raw + \"\\\\Cropped\"):\n",
    "    os.remove(os.path.join(path_arham_raw + \"\\\\Cropped\", file))\n",
    "\n",
    "for file in os.listdir(path_arham_raw + \"\\\\Detected\"):\n",
    "    os.remove(os.path.join(path_arham_raw + \"\\\\Detected\", file))\n",
    "\n",
    "arham_ages = []\n",
    "arham_expressions = []\n",
    "\n",
    "for img in enumerate(images_arham):\n",
    "\n",
    "    # To ignore the first 2 folders in the directory\n",
    "    if(img[1] == \"Cropped\" or img[1] == \"Detected\"):\n",
    "        continue\n",
    "\n",
    "    if(img[1][0] == \"N\"):\n",
    "        exp = \"N\"\n",
    "        arham_expressions.append(\"Not Smiling\")\n",
    "    else:\n",
    "        exp = \"S\"\n",
    "        arham_expressions.append(\"Smiling\")\n",
    "\n",
    "    age = \"\"\n",
    "    for i in range(2,len(img[1])):\n",
    "        if(img[1][i] == \"_\"):\n",
    "            break\n",
    "        else:\n",
    "            age += img[1][i]\n",
    "\n",
    "    arham_ages.append(age)\n",
    "\n",
    "\n",
    "    #Open the image and extract the coordinates of the detected face\n",
    "    image = cv2.imread(path_arham_raw + \"\\\\\" + img[1])\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=3,\n",
    "        minSize=(img_dim, img_dim)\n",
    "    )\n",
    "    \n",
    "    # This is to select the highest detected area, in case there are false positives.\n",
    "    # As in this scenario it is highly likely that the greater area will contain the face rather then\n",
    "    # the smaller falsepostive\n",
    "\n",
    "    if(len(faces) > 1):\n",
    "        cur_max = 0\n",
    "        face = 0\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            length = math.sqrt((x - (x+w))**2 + (y - (y+h))**2 )\n",
    "            \n",
    "            if length > cur_max:\n",
    "                cur_max = length\n",
    "                face = [x,y,w,h]\n",
    "\n",
    "        faces = np.array([face])\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "    \n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2) # Draw a rectangle around the detected area (face)\n",
    "\n",
    "        roi_color = image[y+2:y+2 + h-3, x+2:x+2 + w-3] # The pixel area containing the face\n",
    "        \n",
    "        # Path where image will be saved\n",
    "        cropped_img_path = path_arham_raw + \"\\\\Cropped\\\\\" + age + \"_\" + exp + \"_\" + \"Arham_\" + str(img[0]-1) + \"_.jpg\"\n",
    "        paths_arham_cropped.append(cropped_img_path.replace(\"\\\\\",chr(92)))\n",
    "        \n",
    "\n",
    "        # Resize each image to 64x64 before saving it to the path\n",
    "        cropped_img = cv2.resize(roi_color, (img_dim,img_dim))\n",
    "        cv2.imwrite(cropped_img_path, cropped_img)\n",
    "\n",
    "    # Save the uncropped image with detected face\n",
    "    detected_img_path = path_arham_raw + \"\\\\Detected\\\\\" + age + \"_\" + exp + \"_\" + \"Arham_\" + str(img[0]-1) + \"_.jpg\"\n",
    "    cv2.imwrite(detected_img_path, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(path_unknown_raw + \"\\\\Cropped\"):\n",
    "    os.remove(os.path.join(path_unknown_raw + \"\\\\Cropped\", file))\n",
    "\n",
    "\n",
    "unknown_ages = []\n",
    "unknown_expressions = []\n",
    "\n",
    "#Store all the paths for the unknown images\n",
    "for unknowns in enumerate(images_unknown):\n",
    "    if(unknowns[1] == \"Cropped\"):\n",
    "        continue\n",
    "\n",
    "    \n",
    "    if(unknowns[1][0] == \"N\"):\n",
    "        exp = \"N\"\n",
    "        unknown_expressions.append(\"Not Smiling\")\n",
    "    else:\n",
    "        exp = \"S\"\n",
    "        unknown_expressions.append(\"Smiling\")\n",
    "    \n",
    "    age = \"\"\n",
    "    for i in range(2,len(unknowns[1])):\n",
    "        if(unknowns[1][i] == \"_\"):\n",
    "            break\n",
    "        else:\n",
    "            age += unknowns[1][i]\n",
    "\n",
    "    unknown_ages.append(age)\n",
    "\n",
    "    path = path_unknown_raw + \"\\\\\" + unknowns[1]\n",
    "    image = cv2.imread(path)\n",
    "\n",
    "    img_resize = cv2.resize(image, (img_dim,img_dim))\n",
    "    \n",
    "    new_path = path_unknown_raw + \"\\\\Cropped\\\\\" + age + \"_\" + exp + \"_\" + \"Unknown_\" + str(img[0]-1) + \"_.jpg\"\n",
    "    cv2.imwrite(new_path, img_resize)\n",
    "\n",
    "    np = new_path.replace(\"\\\\\",chr(92))\n",
    "    paths_unknown_cropped.append(np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'paths_unknown_cropped' (list)\n",
      "Stored 'paths_sameed_cropped' (list)\n",
      "Stored 'paths_arham_cropped' (list)\n",
      "Stored 'arham_ages' (list)\n",
      "Stored 'unknown_ages' (list)\n",
      "Stored 'sameed_ages' (list)\n",
      "Stored 'arham_expressions' (list)\n",
      "Stored 'sameed_expressions' (list)\n",
      "Stored 'unknown_expressions' (list)\n"
     ]
    }
   ],
   "source": [
    "%store paths_unknown_cropped\n",
    "%store paths_sameed_cropped\n",
    "%store paths_arham_cropped\n",
    "\n",
    "%store arham_ages\n",
    "%store unknown_ages\n",
    "%store sameed_ages\n",
    "\n",
    "%store arham_expressions\n",
    "%store sameed_expressions\n",
    "%store unknown_expressions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
