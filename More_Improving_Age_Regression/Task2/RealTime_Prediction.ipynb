{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_meNotme_model = pickle.load(open('Sameed_unknown_classifier.pkl', 'rb'))\n",
    "multi_meNotme_model = pickle.load(open('Sameed_Arham_Unknown_classifier.pkl', 'rb'))\n",
    "age_model = pickle.load(open('Age_regression_ridge.pkl', 'rb'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Detection in Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binds face in the frame with a box\n",
    "# If face is detected it returns an image with the face bound, and the pixel area inside the box, excluding the actual boundary\n",
    "# If there are multiple faces in frame, it chooses the one having the greatest area in frame\n",
    "\n",
    "def faceDetect(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=3,\n",
    "        minSize=(64, 64)\n",
    "    )\n",
    "    \n",
    "    if(len(faces) > 1):\n",
    "        cur_max = 0\n",
    "        face = 0\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            length = math.sqrt((x - (x+w))**2 + (y - (y+h))**2 )\n",
    "            \n",
    "            if length > cur_max:\n",
    "                cur_max = length\n",
    "                face = [x,y,w,h]\n",
    "\n",
    "        faces = np.array([face])\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "    \n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2) # Draw a rectangle around the detected area (face)\n",
    "\n",
    "        roi_color = image[y+2:y+2 + h-3, x+2:x+2 + w-3] # The pixel area containing the face\n",
    "\n",
    "        return True,[image,roi_color]\n",
    "    \n",
    "    return False,[]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camera Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starts the camera, provides each frame to the faceDetect() function\n",
    "# If a face is detected it prints the Identity(Sameed or Unknown) and Age using Linear and SGD regression at the bottom of the screen\n",
    "# If no face detected, it prints appropriately\n",
    "# Use esc to exit\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    check, frame = cam.read()\n",
    "    frame = cv2.flip(frame,1)\n",
    "\n",
    "    \n",
    "    frame = cv2.copyMakeBorder(frame,1,250,1,280,cv2.BORDER_CONSTANT,value=0)\n",
    "\n",
    "\n",
    "\n",
    "    cv2.imshow('video', frame)\n",
    "    detected,bound_frame = faceDetect(frame)\n",
    "\n",
    "\n",
    "    if(detected):\n",
    "\n",
    "        cv2.putText(frame,\"Binary Who ->\",(20,530),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "        cv2.putText(frame,\"Multi Who  ->\",(20,570),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "        cv2.putText(frame,\"Age        ->\",(20,670),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "\n",
    "        \n",
    "        frame = bound_frame[0]\n",
    "        cropped_frame = bound_frame[1]\n",
    "\n",
    "        img_resize = cv2.resize(cropped_frame, (64,64)) # The classifier was trained on 64x64 images\n",
    "        img_resize_32 = cv2.resize(cropped_frame, (32,32)) # The classifier was trained on 64x64 images\n",
    "\n",
    "\n",
    "        cur_image = img_resize.flatten()\n",
    "        cur_image_32 = img_resize_32.flatten()\n",
    "        \n",
    "\n",
    "        binary_pred = binary_meNotme_model.predict([cur_image])\n",
    "        multi_pred = multi_meNotme_model.predict([cur_image])\n",
    "        pred_proba = multi_meNotme_model.predict_proba([cur_image])[0]\n",
    "\n",
    "\n",
    "        age_pred = age_model.predict([cur_image_32])\n",
    "\n",
    "        \n",
    "        cv2.putText(frame,str(age_pred),(270,670),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "        cv2.putText(frame,\"(1. Unknown)\",(20,630),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "        cv2.putText(frame,\"(2. Sameed)\",(250,630),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "        cv2.putText(frame,\"(3. Arham)\",(500,630),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "\n",
    "\n",
    "\n",
    "        if(binary_pred == 0):\n",
    "            cv2.putText(frame,\"Unknown\",(270,530),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "            # cv2.imshow('video', frame)\n",
    "\n",
    "        else:\n",
    "            cv2.putText(frame,\"Sameed\",(270,530),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "            # cv2.imshow('video', frame)\n",
    "\n",
    "        if(multi_pred == 0):\n",
    "            cv2.putText(frame,\"Unknown\",(270,570),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "            cv2.putText(frame,str(pred_proba),(20,600),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "\n",
    "        \n",
    "        if(multi_pred == 1):\n",
    "            cv2.putText(frame,\"Sameed\",(270,570),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "            cv2.putText(frame,str(pred_proba),(20,600),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "\n",
    "        if(multi_pred == 2):\n",
    "            cv2.putText(frame,\"Arham\",(270,570),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "            cv2.putText(frame,str(pred_proba),(20,600),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "\n",
    "\n",
    "    else:\n",
    "        cv2.putText(frame,\"Face Not Detected\",(20,580),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "        # cv2.imshow('video', frame)\n",
    "\n",
    "    cv2.imshow('video', frame)\n",
    "\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
