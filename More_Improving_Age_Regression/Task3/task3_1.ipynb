{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 6s 3s/step - loss: 2227.6934 - val_loss: 1727.7053\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 2084.4597 - val_loss: 1461.7771\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 3s 2s/step - loss: 1699.2798 - val_loss: 1123.6638\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 4s 3s/step - loss: 1113.3046 - val_loss: 998.4813\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 1s 445ms/step - loss: 639.2820 - val_loss: 1563.6868\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 2s 610ms/step - loss: 760.5242 - val_loss: 2127.8245\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 1s 504ms/step - loss: 1092.0217 - val_loss: 1778.8777\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 2s 593ms/step - loss: 875.8813 - val_loss: 1296.1554\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 2s 503ms/step - loss: 638.0114 - val_loss: 1066.0012\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 2s 676ms/step - loss: 613.5806 - val_loss: 1002.2674\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 3s 666ms/step - loss: 655.8766 - val_loss: 999.8260\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 2s 721ms/step - loss: 654.6404 - val_loss: 1026.2384\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 2s 646ms/step - loss: 630.7949 - val_loss: 1053.4724\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 2s 602ms/step - loss: 608.5182 - val_loss: 1070.9873\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 1s 476ms/step - loss: 601.6683 - val_loss: 1121.6368\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 2s 750ms/step - loss: 595.2358 - val_loss: 1224.5128\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 2s 690ms/step - loss: 615.7869 - val_loss: 1333.7510\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 2s 544ms/step - loss: 656.9092 - val_loss: 1272.8606\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 2s 568ms/step - loss: 627.6384 - val_loss: 1120.0439\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 2s 566ms/step - loss: 609.9107 - val_loss: 1060.9835\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 2s 658ms/step - loss: 606.3505 - val_loss: 1072.8799\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 2s 639ms/step - loss: 603.4914 - val_loss: 1105.8127\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 2s 612ms/step - loss: 599.3589 - val_loss: 1115.8093\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 2s 512ms/step - loss: 599.1400 - val_loss: 1134.6453\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 1s 558ms/step - loss: 598.2994 - val_loss: 1183.5398\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 1s 530ms/step - loss: 605.6867 - val_loss: 1200.2275\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 1s 482ms/step - loss: 608.1588 - val_loss: 1178.9785\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 1s 496ms/step - loss: 603.5204 - val_loss: 1147.5651\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 1s 481ms/step - loss: 599.0825 - val_loss: 1116.9994\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 1s 498ms/step - loss: 596.3359 - val_loss: 1083.9626\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 1s 510ms/step - loss: 601.9424 - val_loss: 1071.4785\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 1s 506ms/step - loss: 599.7849 - val_loss: 1120.2926\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 1s 522ms/step - loss: 592.7576 - val_loss: 1237.1488\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 1s 501ms/step - loss: 615.9507 - val_loss: 1358.7097\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 1s 534ms/step - loss: 662.9375 - val_loss: 1309.8445\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 1s 489ms/step - loss: 635.0286 - val_loss: 1141.7463\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 1s 473ms/step - loss: 598.7600 - val_loss: 1045.3014\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 1s 512ms/step - loss: 613.9526 - val_loss: 1021.7609\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 1s 482ms/step - loss: 622.8890 - val_loss: 1044.2455\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 1s 515ms/step - loss: 608.8272 - val_loss: 1101.3129\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 1s 488ms/step - loss: 602.2496 - val_loss: 1128.9225\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 1s 501ms/step - loss: 594.8591 - val_loss: 1097.0065\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 1s 487ms/step - loss: 600.1948 - val_loss: 1093.1759\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 1s 509ms/step - loss: 595.5167 - val_loss: 1134.5323\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 1s 479ms/step - loss: 595.2142 - val_loss: 1170.0013\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 1s 533ms/step - loss: 601.8455 - val_loss: 1140.1230\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 1s 493ms/step - loss: 592.2641 - val_loss: 1062.1793\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 606.4832 - val_loss: 1031.8934\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 1s 495ms/step - loss: 614.2820 - val_loss: 1040.5385\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 1s 475ms/step - loss: 612.2970 - val_loss: 1041.4158\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the path to the folder containing the images\n",
    "folder_path = r\"C:\\Users\\Sameed\\Desktop\\ML_Overall_Work\\More_Improving_Age_Regression\\Task2\\Dataset\\Unknown\\Cropped\"\n",
    "\n",
    "# Define the image size\n",
    "img_size = (200, 200)\n",
    "\n",
    "# Load the images and labels from the folder\n",
    "images = []\n",
    "labels = []\n",
    "for file_name in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    img = cv2.imread(file_path)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    images.append(img)\n",
    "    label = int(os.path.splitext(file_name)[0].split('_')[0])\n",
    "    labels.append(label)\n",
    "\n",
    "# Convert the images and labels to numpy arrays\n",
    "x = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Normalize the input data\n",
    "x = x / 255.0\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize the input data\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Define the linear regression model\n",
    "inputs = keras.Input(shape=(200, 200, 3))\n",
    "x = tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1, activation='linear')(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "\n",
    "# Define the checkpoint callback\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='linear_regression_model.h5',\n",
    "                                                         monitor='val_loss',\n",
    "                                                         save_best_only=True,\n",
    "                                                         save_weights_only=False,\n",
    "                                                         mode='auto')\n",
    "\n",
    "# Train the model on the training data with checkpointing\n",
    "history = model.fit(x_train, y_train, epochs=50, batch_size=32, validation_data=(x_test, y_test), callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age_model.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model,'age_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
