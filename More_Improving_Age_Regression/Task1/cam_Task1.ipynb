{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model = pickle.load(open('ridge.pkl', 'rb'))\n",
    "SGD_model = pickle.load(open('sgd.pkl', 'rb'))\n",
    "MeClf_model = pickle.load(open('Meclassifier.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face Detection in Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binds face in the frame with a box\n",
    "# If face is detected it returns an image with the face bound, and the pixel area inside the box, excluding the actual boundary\n",
    "# If there are multiple faces in frame, it chooses the one having the greatest area in frame\n",
    "\n",
    "def faceDetect(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=3,\n",
    "        minSize=(64, 64)\n",
    "    )\n",
    "    \n",
    "    if(len(faces) > 1):\n",
    "        cur_max = 0\n",
    "        face = 0\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            length = math.sqrt((x - (x+w))**2 + (y - (y+h))**2 )\n",
    "            \n",
    "            if length > cur_max:\n",
    "                cur_max = length\n",
    "                face = [x,y,w,h]\n",
    "\n",
    "        faces = np.array([face])\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "    \n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2) # Draw a rectangle around the detected area (face)\n",
    "\n",
    "        roi_color = image[y+2:y+2 + h-3, x+2:x+2 + w-3] # The pixel area containing the face\n",
    "\n",
    "        return True,[image,roi_color]\n",
    "    \n",
    "    return False,[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camera Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starts the camera, provides each frame to the faceDetect() function\n",
    "# If a face is detected it prints the Identity(Sameed or Unknown) and Age using Linear and SGD regression at the bottom of the screen\n",
    "# If no face detected, it prints appropriately\n",
    "# Use esc to exit\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    check, frame = cam.read()\n",
    "    frame = cv2.flip(frame,1)\n",
    "\n",
    "    \n",
    "    frame = cv2.copyMakeBorder(frame,1,150,1,1,cv2.BORDER_CONSTANT,value=0)\n",
    "\n",
    "    cv2.putText(frame,\"Who:\",(20,530),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "    cv2.putText(frame,\"Age:\",(370,530),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "\n",
    "    cv2.imshow('video', frame)\n",
    "    detected,bound_frame = faceDetect(frame)\n",
    "\n",
    "\n",
    "    if(detected):\n",
    "        frame = bound_frame[0]\n",
    "        cropped_frame = bound_frame[1]\n",
    "\n",
    "        img_resize_clf = cv2.resize(cropped_frame, (64,64)) # The classifier was trained on 64x64 images\n",
    "        img_resize_reg = cv2.resize(cropped_frame, (32,32)) # The regressors were trained on 32x32 images\n",
    "\n",
    "        cur_image_clf = img_resize_clf.flatten()\n",
    "        cur_image_ref = img_resize_reg.flatten()\n",
    "\n",
    "        me_pred = MeClf_model.predict([cur_image_clf])\n",
    "        ols_pred = ridge_model.predict([cur_image_ref])\n",
    "        sgd_pred = SGD_model.predict([cur_image_ref])\n",
    "\n",
    "        cv2.putText(frame,\"Ridge - \" + str(int(ols_pred)),(370,580),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),1)\n",
    "        cv2.putText(frame,\"SGD - \" + str(int(sgd_pred)),(370,620),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),1)\n",
    "\n",
    "        if(me_pred == 0):\n",
    "            cv2.putText(frame,\"Unknown\",(20,580),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "            # cv2.imshow('video', frame)\n",
    "\n",
    "        else:\n",
    "            cv2.putText(frame,\"Sameed\",(20,580),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "            # cv2.imshow('video', frame)\n",
    "\n",
    "    else:\n",
    "        cv2.putText(frame,\"Face Not Detected\",(20,580),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "        # cv2.imshow('video', frame)\n",
    "\n",
    "    cv2.imshow('video', frame)\n",
    "\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
