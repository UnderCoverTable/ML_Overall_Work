{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLS_model = pickle.load(open('OLS.pkl', 'rb'))\n",
    "SGD_model = pickle.load(open('SGD.pkl', 'rb'))\n",
    "MeClf_model = pickle.load(open('Meclassifier.pkl', 'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faceDetect(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faceCascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=3,\n",
    "        minSize=(img_dim, img_dim)\n",
    "    )\n",
    "    \n",
    "    if(len(faces) > 1):\n",
    "        cur_max = 0\n",
    "        face = 0\n",
    "\n",
    "        for (x, y, w, h) in faces:\n",
    "            length = math.sqrt((x - (x+w))**2 + (y - (y+h))**2 )\n",
    "            \n",
    "            if length > cur_max:\n",
    "                cur_max = length\n",
    "                face = [x,y,w,h]\n",
    "\n",
    "        faces = np.array([face])\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "    \n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2) # Draw a rectangle around the detected area (face)\n",
    "\n",
    "        roi_color = image[y+2:y+2 + h-3, x+2:x+2 + w-3] # The pixel area containing the face\n",
    "\n",
    "        return True,[image,roi_color]\n",
    "    \n",
    "    return False,[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m cv2\u001b[39m.\u001b[39mputText(frame,\u001b[39m\"\u001b[39m\u001b[39mAge:\u001b[39m\u001b[39m\"\u001b[39m,(\u001b[39m370\u001b[39m,\u001b[39m530\u001b[39m),cv2\u001b[39m.\u001b[39mFONT_HERSHEY_SIMPLEX,\u001b[39m1\u001b[39m,(\u001b[39m255\u001b[39m,\u001b[39m255\u001b[39m,\u001b[39m255\u001b[39m),\u001b[39m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mvideo\u001b[39m\u001b[39m'\u001b[39m, frame)\n\u001b[1;32m---> 17\u001b[0m detected,bound_frame \u001b[39m=\u001b[39m faceDetect(frame)\n\u001b[0;32m     20\u001b[0m \u001b[39mif\u001b[39;00m(detected):\n\u001b[0;32m     21\u001b[0m     frame \u001b[39m=\u001b[39m bound_frame[\u001b[39m0\u001b[39m]\n",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m, in \u001b[0;36mfaceDetect\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfaceDetect\u001b[39m(image):\n\u001b[0;32m      2\u001b[0m     gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(image, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m----> 4\u001b[0m     faceCascade \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mCascadeClassifier(cv2\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mhaarcascades \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mhaarcascade_frontalface_default.xml\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      5\u001b[0m     faces \u001b[39m=\u001b[39m faceCascade\u001b[39m.\u001b[39mdetectMultiScale(\n\u001b[0;32m      6\u001b[0m         gray,\n\u001b[0;32m      7\u001b[0m         scaleFactor\u001b[39m=\u001b[39m\u001b[39m1.3\u001b[39m,\n\u001b[0;32m      8\u001b[0m         minNeighbors\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[0;32m      9\u001b[0m         minSize\u001b[39m=\u001b[39m(img_dim, img_dim)\n\u001b[0;32m     10\u001b[0m     )\n\u001b[0;32m     12\u001b[0m     \u001b[39mif\u001b[39;00m(\u001b[39mlen\u001b[39m(faces) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cv2.destroyAllWindows()\n",
    "\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    check, frame = cam.read()\n",
    "    frame = cv2.flip(frame,1)\n",
    "\n",
    "    \n",
    "    frame = cv2.copyMakeBorder(frame,1,150,1,1,cv2.BORDER_CONSTANT,value=0)\n",
    "\n",
    "    cv2.putText(frame,\"Who:\",(20,530),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "    cv2.putText(frame,\"Age:\",(370,530),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "\n",
    "    cv2.imshow('video', frame)\n",
    "    detected,bound_frame = faceDetect(frame)\n",
    "\n",
    "\n",
    "    if(detected):\n",
    "        frame = bound_frame[0]\n",
    "        cropped_frame = bound_frame[1]\n",
    "\n",
    "        img_resize_clf = cv2.resize(cropped_frame, (64,64))\n",
    "        img_resize_reg = cv2.resize(cropped_frame, (32,32))\n",
    "\n",
    "        cur_image_clf = img_resize_clf.flatten()\n",
    "        cur_image_ref = img_resize_reg.flatten()\n",
    "\n",
    "        me_pred = MeClf_model.predict([cur_image_clf])\n",
    "        ols_pred = OLS_model.predict([cur_image_ref])\n",
    "        sgd_pred = SGD_model.predict([cur_image_ref])\n",
    "\n",
    "        cv2.putText(frame,\"OLS - \" + str(int(ols_pred)),(370,580),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),1)\n",
    "        cv2.putText(frame,\"SGD - \" + str(int(sgd_pred)),(370,620),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),1)\n",
    "\n",
    "        if(me_pred == 0):\n",
    "            cv2.putText(frame,\"Unknown\",(20,580),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "            # cv2.imshow('video', frame)\n",
    "\n",
    "        else:\n",
    "            cv2.putText(frame,\"Sameed\",(20,580),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "            # cv2.imshow('video', frame)\n",
    "\n",
    "    else:\n",
    "        cv2.putText(frame,\"Face Not Detected\",(20,580),cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),1)\n",
    "        # cv2.imshow('video', frame)\n",
    "\n",
    "    cv2.imshow('video', frame)\n",
    "\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
